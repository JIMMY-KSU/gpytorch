{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.lazy import NonLazyTensor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "d = 1\n",
    "jitter_val = float(1e-1)\n",
    "lengthscale = 1\n",
    "\n",
    "rbf = RBFKernel()\n",
    "rbf.initialize(lengthscale=lengthscale)\n",
    "\n",
    "kernel = ScaleKernel(rbf).cuda().half()\n",
    "X = torch.randn(N, d).cuda().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HalfsiesNonLazyTensor(NonLazyTensor):\n",
    "    def _get_indices(self, left_indices, right_indices, *batch_indices):\n",
    "        return super()._get_indices(left_indices, right_indices, *batch_indices).float()\n",
    "    \n",
    "    def _getitem(self, *indices):\n",
    "        return super()._getitem(*indices).float()\n",
    "    \n",
    "    def _matmul(self, rhs):\n",
    "        return super()._matmul(rhs.half()).float()\n",
    "    \n",
    "    def _t_matmul(self, rhs):\n",
    "        return super()._t_matmul(rhs.half()).float()\n",
    "    \n",
    "    def _quad_form_derivative(self, left_vecs, right_vecs):\n",
    "        return (res.float() for res in super()._quad_form_derivative(left_vecs, right_vecs))\n",
    "    \n",
    "    def diag(self):\n",
    "        return super().diag().float()\n",
    "    \n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return torch.float32\n",
    "    \n",
    "    def evaluate(self):\n",
    "        return self.tensor.float()\n",
    "\n",
    "# can't use add_jitter because it makes a float :(\n",
    "lt = HalfsiesNonLazyTensor(kernel(X).evaluate()).add_diag(torch.tensor(jitter_val, device=X.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mixed precision...\n",
      "Final CG residual norm after 8.329125557793304e-05 iterations: 14\n",
      "Running fp32...\n",
      "Final CG residual norm after 1.0387577020765093e-07 iterations: 10\n"
     ]
    }
   ],
   "source": [
    "rhs = torch.randn(N, device=X.device)\n",
    "\n",
    "import gpytorch\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.max_cg_iterations(1000), gpytorch.settings.cg_tolerance(0.0001):\n",
    "    print('Running mixed precision...')\n",
    "    solve_half = lt.inv_matmul(rhs)\n",
    "    print('Running fp32...')\n",
    "    solve_float = kernel.float()(X.float()).add_diag(torch.tensor(jitter_val, device=X.device)).inv_matmul(rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
